{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "utSjrT6RsX7n"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, embed_size, heads):\n",
    "    super(SelfAttention, self).__init__()\n",
    "    self.embed_size = embed_size\n",
    "    self.heads = heads\n",
    "    self.head_dim = embed_size // heads\n",
    "\n",
    "    assert (self.head_dim * heads == embed_size), \"Embed size need to be div by heads\"\n",
    "\n",
    "    self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "    self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "    self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "    self.fc_out = nn.Linear(heads*self.head_dim, embed_size) ## fully connected\n",
    "\n",
    "  def forward(self, values, keys, query, mask):\n",
    "    N = query.shape[0] # how many examples we are sending in at the same time\n",
    "    value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1] ## corresponds to source sentence lenght and target sentence length\n",
    "    \n",
    "    # Split embedding into self.heads pieces\n",
    "    values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "    keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "    queries = query.reshape(N, query_len, self.heads, self.head_dim)   \n",
    "\n",
    "    values = self.values(values)\n",
    "    keys = self.keys(keys)\n",
    "    queries = self.queries(queries)\n",
    "\n",
    "    energy = torch.einsum(\"nqhd, nkhd->nhqk\", [queries, keys])    # used for matrix multiplication\n",
    "    # queries shape: (N, query_len, heads, heads_dim)\n",
    "    # keys shape: (N, keys_len, heads, heads_dim)\n",
    "    # energy shape: (N, heads, query_len, keys_len)\n",
    "    if mask is not None:\n",
    "      energy = energy.masked_fill(mask == 0, float(\"-1e20\"))  # if element of mask is zero, we want to shut it off (not inpact other), set it to -Inf\n",
    "    \n",
    "    attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim = 3) ## normalizing across key length, i.e.\n",
    "\n",
    "    out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "        N, query_len, self.heads*self.head_dim\n",
    "    )\n",
    "    # attention shape: (N, heads, query_len, key_len)\n",
    "    # values shape: (N, value_len, heads, heads_dim)\n",
    "    # out: (N, query_len, heads, head_dim) \n",
    "    # then flatten last two dim, to concat.\n",
    "\n",
    "    out = self.fc_out(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "    super(TransformerBlock, self).__init__()\n",
    "    self.attention = SelfAttention(embed_size, heads)\n",
    "    self.norm1 = nn.LayerNorm(embed_size) # normalization, LayerNorm\n",
    "    self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "    self.feed_forward = nn.Sequential(\n",
    "        nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "    )\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, value, key, query, mask):\n",
    "    attention = self.attention(value, key, query, mask)\n",
    "\n",
    "    x = self.dropout(self.norm1(attention + query)) # send in skip connection\n",
    "    forward = self.feed_forward(x)\n",
    "    out = self.dropout(self.norm2(forward + x))\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      src_vocab_size,\n",
    "      embed_size,\n",
    "      num_layers,\n",
    "      heads,\n",
    "      device,\n",
    "      forward_expansion,\n",
    "      dropout,\n",
    "      max_length\n",
    "  ):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.embed_size = embed_size\n",
    "    self.device = device\n",
    "    print(src_vocab_size, embed_size)\n",
    "    self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "    print(src_vocab_size, embed_size)\n",
    "    \n",
    "\n",
    "    self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "    self.layers = nn.ModuleList(\n",
    "        [\n",
    "         TransformerBlock(\n",
    "             embed_size,\n",
    "             heads,\n",
    "             dropout=dropout,\n",
    "             forward_expansion=forward_expansion,\n",
    "         )\n",
    "       for _ in range(num_layers) ]\n",
    "    )\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, mask):\n",
    "    N, seq_length = x.shape\n",
    "    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "\n",
    "    out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "\n",
    "    for layer in self.layers:\n",
    "      out = layer(out, out, out, mask)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "  def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "    super(DecoderBlock, self).__init__()\n",
    "    self.attention = SelfAttention(embed_size, heads)\n",
    "    self.norm = nn.LayerNorm(embed_size)\n",
    "    self.transformer_block = TransformerBlock(\n",
    "        embed_size, heads, dropout, forward_expansion\n",
    "    )\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, value, key, src_mask, trg_mask):\n",
    "    attention = self.attention(x, x, x, trg_mask)\n",
    "    query = self.dropout(self.norm(attention + x))\n",
    "    out = self.transformer_block(value, key, query, src_mask)\n",
    "    return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, trg_vocab_size, embed_size, num_layers, heads, forward_expansion, dropout, device, max_length):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.device = device\n",
    "    self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "    self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "    self.layers = nn.ModuleList(\n",
    "        [DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "        for _ in range(num_layers)]\n",
    "    )\n",
    "    self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "    N, seq_length = x.shape\n",
    "    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "    x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
    "    for layer in self.layers:\n",
    "      x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "    out = self.fc_out(x)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "  def __init__(self, \n",
    "               src_vocab_size, \n",
    "               trg_vocab_size, \n",
    "               src_pad_idx, \n",
    "               trg_pad_idx, \n",
    "               embed_size=256, \n",
    "               num_layers=6, \n",
    "               forward_expansion=4, \n",
    "               heads=8, \n",
    "               dropout=0, \n",
    "               device=\"cuda\", \n",
    "               max_length=100):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(\n",
    "        src_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length\n",
    "    )\n",
    "\n",
    "    self.decoder = Decoder(\n",
    "        trg_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        device,\n",
    "        max_length\n",
    "    )\n",
    "\n",
    "    self.src_pad_idx = src_pad_idx\n",
    "    self.trg_pad_idx = trg_pad_idx\n",
    "    self.device = device\n",
    "\n",
    "  def make_src_mask(self, src):\n",
    "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    # (N, 1, 1 src_len)\n",
    "    return src_mask.to(self.device)\n",
    "\n",
    "  def make_trg_mask(self, trg):\n",
    "    N, trg_len = trg.shape\n",
    "    trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "        N, 1, trg_len, trg_len\n",
    "    )\n",
    "    return trg_mask.to(self.device)\n",
    "\n",
    "  def forward(self, src, trg):\n",
    "    src_mask = self.make_src_mask(src)\n",
    "    trg_mask = self.make_trg_mask(trg)\n",
    "    enc_src = self.encoder(src, src_mask)\n",
    "    out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"traj_data_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>X_REL</th>\n",
       "      <th>Y_REL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134363.000000</td>\n",
       "      <td>134363.000000</td>\n",
       "      <td>1.343630e+05</td>\n",
       "      <td>1.343630e+05</td>\n",
       "      <td>134363.000000</td>\n",
       "      <td>134363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67181.000000</td>\n",
       "      <td>1522.586002</td>\n",
       "      <td>6.037205e+06</td>\n",
       "      <td>1.893112e+06</td>\n",
       "      <td>25.013277</td>\n",
       "      <td>-20.563577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38787.401447</td>\n",
       "      <td>906.737134</td>\n",
       "      <td>1.109129e+06</td>\n",
       "      <td>1.831537e+05</td>\n",
       "      <td>34.361927</td>\n",
       "      <td>63.308456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.230484e+06</td>\n",
       "      <td>1.375551e+06</td>\n",
       "      <td>-104.242000</td>\n",
       "      <td>-329.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33590.500000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>6.042875e+06</td>\n",
       "      <td>1.873242e+06</td>\n",
       "      <td>-0.464000</td>\n",
       "      <td>-58.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67181.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>6.451159e+06</td>\n",
       "      <td>1.873308e+06</td>\n",
       "      <td>14.445000</td>\n",
       "      <td>-18.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100771.500000</td>\n",
       "      <td>2262.000000</td>\n",
       "      <td>6.451216e+06</td>\n",
       "      <td>1.874247e+06</td>\n",
       "      <td>42.681000</td>\n",
       "      <td>12.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>134362.000000</td>\n",
       "      <td>3363.000000</td>\n",
       "      <td>6.452528e+06</td>\n",
       "      <td>2.133628e+06</td>\n",
       "      <td>236.273000</td>\n",
       "      <td>366.318000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0     Vehicle_ID             X             Y  \\\n",
       "count  134363.000000  134363.000000  1.343630e+05  1.343630e+05   \n",
       "mean    67181.000000    1522.586002  6.037205e+06  1.893112e+06   \n",
       "std     38787.401447     906.737134  1.109129e+06  1.831537e+05   \n",
       "min         0.000000       2.000000  2.230484e+06  1.375551e+06   \n",
       "25%     33590.500000     753.000000  6.042875e+06  1.873242e+06   \n",
       "50%     67181.000000    1479.000000  6.451159e+06  1.873308e+06   \n",
       "75%    100771.500000    2262.000000  6.451216e+06  1.874247e+06   \n",
       "max    134362.000000    3363.000000  6.452528e+06  2.133628e+06   \n",
       "\n",
       "               X_REL          Y_REL  \n",
       "count  134363.000000  134363.000000  \n",
       "mean       25.013277     -20.563577  \n",
       "std        34.361927      63.308456  \n",
       "min      -104.242000    -329.272000  \n",
       "25%        -0.464000     -58.563500  \n",
       "50%        14.445000     -18.858000  \n",
       "75%        42.681000      12.638500  \n",
       "max       236.273000     366.318000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['Vehicle_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "values = [[1,2,3],[2,2,3], [1,6,3], [1,2,5]]\n",
    "yvalues = [[1,2,4],[2,2,3], [1,6,3], [1,2,5]]\n",
    "test_dataset, training_dataset, x, y = train_test_split(values, yvalues, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "iW2pPb1o5-hJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ############## TEST ##################\n",
    "# test1 = pd.read_csv(\"test_traj_data.csv\", sep=\"\\t\")\n",
    "# test1.columns = [\"Frame\", \"Vehicle_ID\", \"X\", \"Y\"]\n",
    "\n",
    "# ############### TRAIN ###############\n",
    "# train1 = pd.read_csv(\"students_1.txt\", sep=\"\\t\", header=None)\n",
    "# train1.columns = [\"Frame\", \"Ped\", \"X\", \"Y\"]\n",
    "\n",
    "def preprocess_dataset(data, max = 10, max_len = 40, input_len = 30):\n",
    "    scaler = MinMaxScaler(feature_range=(0, max))\n",
    "    data[['X_REL', 'Y_REL']] = scaler.fit_transform(data[['X_REL', 'Y_REL']])\n",
    "    global map_dict\n",
    "    map_dict = {}\n",
    "    unique_peds = data['Vehicle_ID'].unique()\n",
    "    unique_peds = sorted(unique_peds)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    seq = []\n",
    "    for ped in unique_peds:\n",
    "        if (len(data[data['Vehicle_ID'] == ped]) >= max_len):\n",
    "          seq_inner = []\n",
    "          target_inner = 0\n",
    "          i = 0\n",
    "          for indx, row in data[data['Vehicle_ID'] == ped].iterrows():\n",
    "            x = round(row['X_REL'])\n",
    "            y = round(row['Y_REL'])\n",
    "            ## Cantor pairing function:\n",
    "            bin = y * max + x\n",
    "            #print(\"X: \", x, \" Y: \", y, \" Bin: \", bin)\n",
    "            map_dict[int(bin)] = [int(x), int(y)]\n",
    "            i += 1\n",
    "            if i == max_len:\n",
    "              break\n",
    "            seq_inner.append(int(bin))\n",
    "          inputs.append([seq_inner[0:input_len]])\n",
    "          outputs.append([seq_inner[input_len + 1:]])\n",
    "    train_inputs, test_inputs = train_test_split(inputs, train_size=0.7)\n",
    "    train_inputs, test_inputs, train_targets, test_targets = train_test_split(inputs, outputs, train_size=0.8)\n",
    "    \n",
    "    return torch.tensor(train_inputs), torch.tensor(test_inputs), torch.tensor(train_targets), torch.tensor(test_targets)\n",
    "\n",
    "train_data_inputs, test_data_inputs, train_data_targets, test_data_targets = preprocess_dataset(data, max = 50, max_len = 50, input_len = 20)\n",
    "#test_data_inputs, test_data_targets = preprocess_dataset(test, max = 50, max_len = 50, input_len = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onO-14Ls0sgJ",
    "outputId": "871da3f1-4d8e-4006-ca17-ca2fd242a045"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([536, 1, 20])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoKNZ8IUFp4j",
    "outputId": "4daf433a-77e3-4da5-93c2-b3fbeae0c7f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2143, 1, 28])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjKmqw9F5lND",
    "outputId": "64f8b79e-74ad-4ef5-ff46-eb41bd5b2e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550 256\n",
      "2550 256\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)\n",
    "  # trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n",
    "  x = torch.tensor([[1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(device)\n",
    "  trg = torch.tensor([[1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n",
    "\n",
    "  src_pad_idx = -999\n",
    "  trg_pad_idx = -999\n",
    "  src_vocab_size = 50*50 + 50\n",
    "  trg_vocab_size = 50*50 + 50\n",
    "  model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device, dropout=0.15).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "YL0Uoilr5HId"
   },
   "outputs": [],
   "source": [
    "bptt = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "import math\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = 50*50 + 50\n",
    "    for batch, i in enumerate(range(0, train_data_inputs.size(0), 1)):\n",
    "      # data, targets = get_batch(train_data, i)\n",
    "      data = train_data_inputs[i,:,:]\n",
    "      targets = train_data_targets[i,:,:]\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data, targets[:, :])\n",
    "      # print(output.shape)\n",
    "      # print(targets.shape)\n",
    "      loss = criterion(output[0,:,:], targets[0,:])\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss += loss.item()\n",
    "      log_interval = 200\n",
    "        \n",
    "    cur_loss = total_loss / train_data_inputs.size(0)\n",
    "    print('lr {:02.2f} | '\n",
    "                'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                  scheduler.get_lr()[0],\n",
    "                  cur_loss, math.exp(cur_loss)))\n",
    "\n",
    "def evaluate(eval_model, data_source_inputs, data_source_targets, get_preds=False):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = 50*50 + 50\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source_inputs.size(0), 1):\n",
    "            # data, targets = get_batch(data_source, i)\n",
    "            data = data_source_inputs[i,:,:]\n",
    "            targets = data_source_targets[i,:,:]\n",
    "            output = eval_model(data, targets[:, :])\n",
    "            output_flat = output\n",
    "            if get_preds:\n",
    "              # print(data)\n",
    "              # print(torch.argmax(output[0,:,:], dim=1).shape)\n",
    "              # print(targets[0,:-1].shape)\n",
    "              # print(torch.argmax(output[0,:,:], dim=1))\n",
    "              # print(targets[0,:-1])\n",
    "              # print(\"--\" * 30)\n",
    "              vis_trajectory(torch.argmax(output[0,:,:], dim=1), targets[0,:])\n",
    "\n",
    "            total_loss += 1 * criterion(output[0,:,:], targets[0,:]).item()\n",
    "    return total_loss / (data_source_inputs.size(0))\n",
    "\n",
    "\n",
    "\n",
    "def get_predictions(eval_model, data_source_inputs, data_source_targets):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    ntokens = 50*50 + 50\n",
    "    preds_list = []\n",
    "    target_list = []\n",
    "    inputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source_inputs.size(0), 1):\n",
    "            # data, targets = get_batch(data_source, i)\n",
    "            data = data_source_inputs[i,:,:]\n",
    "            targets = data_source_targets[i,:,:]\n",
    "            output = eval_model(data, targets[:, :])\n",
    "              # print(data)\n",
    "              # print(torch.argmax(output[0,:,:], dim=1).shape)\n",
    "              # print(targets[0,:-1].shape)\n",
    "              # print(torch.argmax(output[0,:,:], dim=1))\n",
    "              # print(targets[0,:-1])\n",
    "              # print(\"--\" * 30)\n",
    "              # vis_trajectory(torch.argmax(output[0,:,:], dim=1), targets[0,:-1])\n",
    "            preds_list.append(torch.argmax(output[0,:,:], dim=1).tolist())\n",
    "            target_list.append(targets[0,:].tolist())\n",
    "            inputs_list.append(data[0,:].tolist())\n",
    "\n",
    "    return inputs_list, target_list, preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQN0OkjK5s9s",
    "outputId": "35c5277e-b121-406d-d40d-eef602954629"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daavi\\Anaconda3\\envs\\transformers\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.50 | loss  2.13 | ppl     8.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 236.51s | valid loss  0.97 | valid ppl     2.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.45 | loss  0.81 | ppl     2.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 221.58s | valid loss  0.56 | valid ppl     1.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.43 | loss  0.52 | ppl     1.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 217.91s | valid loss  0.37 | valid ppl     1.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.41 | loss  0.37 | ppl     1.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 214.76s | valid loss  0.27 | valid ppl     1.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.39 | loss  0.29 | ppl     1.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 213.27s | valid loss  0.22 | valid ppl     1.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.37 | loss  0.23 | ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 216.63s | valid loss  0.18 | valid ppl     1.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.35 | loss  0.19 | ppl     1.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 213.46s | valid loss  0.15 | valid ppl     1.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.33 | loss  0.15 | ppl     1.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 214.16s | valid loss  0.14 | valid ppl     1.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.32 | loss  0.13 | ppl     1.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 214.66s | valid loss  0.12 | valid ppl     1.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.30 | loss  0.11 | ppl     1.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 218.85s | valid loss  0.11 | valid ppl     1.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.28 | loss  0.10 | ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 221.50s | valid loss  0.10 | valid ppl     1.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.27 | loss  0.09 | ppl     1.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 213.53s | valid loss  0.09 | valid ppl     1.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "lr 0.26 | loss  0.08 | ppl     1.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 214.02s | valid loss  0.09 | valid ppl     1.09\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-82f465453302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mepoch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m   \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m89\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-da5ea9b01c8e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m       \u001b[1;31m# print(targets.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\transformers\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\transformers\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 50 # The number of epochs\n",
    "best_model = None\n",
    "early_stopping = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  epoch_start_time = time.time()\n",
    "  train()\n",
    "  val_loss = evaluate(model, test_data_inputs, test_data_targets)\n",
    "  print('-' * 89)\n",
    "  print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "        'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                    val_loss, math.exp(val_loss)))\n",
    "  print('-' * 89)\n",
    "\n",
    "  early_stopping = early_stopping + 1\n",
    "\n",
    "  if val_loss < best_val_loss:\n",
    "    early_stopping = 0\n",
    "    best_val_loss = val_loss\n",
    "    best_model = model\n",
    "\n",
    "\n",
    "  if early_stopping > 10:\n",
    "    break\n",
    "\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wZNzdAbBY1gB",
    "outputId": "c567b05f-2f08-486f-9969-667d40eba46a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[15, 24], [15, 24], [15, 24], [15, 24], [15, 24], [15, 24], [15, 24], [15, 24], [15, 25], [15, 25], [15, 25], [15, 25], [15, 25], [16, 25], [16, 25], [16, 26], [16, 26], [16, 26], [16, 26], [16, 26]]\n",
      "Preds:  [[16, 27], [16, 27], [16, 27], [16, 27], [16, 27], [16, 27], [16, 28], [16, 28], [16, 28], [16, 28], [16, 28], [16, 28], [16, 29], [16, 29], [16, 29], [16, 29], [16, 29], [16, 30], [16, 30], [16, 30], [16, 30], [16, 30], [16, 31], [16, 31], [17, 31], [17, 31], [17, 31], [17, 32]]\n",
      "Truth:  [[16, 27], [16, 27], [16, 27], [16, 27], [16, 27], [16, 27], [16, 28], [16, 28], [16, 28], [16, 28], [16, 28], [16, 28], [16, 29], [16, 29], [16, 29], [16, 29], [16, 29], [16, 30], [16, 30], [16, 30], [16, 30], [16, 30], [16, 31], [16, 31], [17, 31], [17, 31], [17, 31], [17, 32]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[15, 24], [16, 23], [16, 23], [16, 23], [17, 23], [17, 23], [17, 23], [18, 22], [18, 22], [19, 22], [19, 22], [19, 21], [20, 21], [20, 21], [21, 21], [21, 21], [21, 20], [22, 20], [22, 20], [22, 20]]\n",
      "Preds:  [[23, 19], [24, 19], [24, 19], [24, 19], [25, 19], [25, 18], [26, 18], [26, 18], [26, 18], [27, 17], [27, 17], [28, 17], [28, 17], [28, 17], [29, 16], [29, 16], [30, 16], [30, 16], [30, 16], [31, 15], [31, 15], [32, 15], [32, 15], [32, 14], [33, 14], [33, 14], [34, 14], [34, 14]]\n",
      "Truth:  [[23, 19], [24, 19], [24, 19], [24, 19], [25, 19], [25, 18], [26, 18], [26, 18], [26, 18], [27, 17], [27, 17], [28, 17], [28, 17], [28, 17], [29, 16], [29, 16], [30, 16], [30, 16], [30, 16], [31, 15], [31, 15], [32, 15], [32, 15], [32, 14], [33, 14], [33, 14], [34, 14], [34, 14]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[15, 24], [15, 24], [15, 24], [15, 24], [15, 25], [15, 25], [15, 25], [15, 25], [15, 25], [15, 26], [15, 26], [15, 26], [15, 26], [15, 27], [15, 27], [14, 27], [14, 27], [14, 27], [14, 28], [14, 28]]\n",
      "Preds:  [[14, 28], [14, 29], [14, 29], [14, 29], [14, 29], [14, 29], [14, 30], [14, 30], [14, 30], [14, 30], [14, 31], [13, 31], [13, 31], [13, 32], [13, 32], [13, 32], [13, 33], [13, 33], [13, 33], [13, 34], [13, 34], [13, 34], [12, 34], [12, 35], [12, 35], [12, 35], [12, 36], [12, 36]]\n",
      "Truth:  [[14, 28], [14, 29], [14, 29], [14, 29], [14, 29], [14, 29], [14, 30], [14, 30], [14, 30], [14, 30], [14, 31], [13, 31], [13, 31], [13, 32], [13, 32], [13, 32], [13, 33], [13, 33], [13, 33], [13, 34], [13, 34], [13, 34], [12, 34], [12, 35], [12, 35], [12, 35], [12, 36], [12, 36]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-684dffd4608c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvis_trajectory_scatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-6a8110ff888a>\u001b[0m in \u001b[0;36mvis_trajectory_scatter\u001b[1;34m(best_model, data_src_inputs, data_src_targets, lag_time)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Preds: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxy_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Truth: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxy_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlag_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vis_trajectory_scatter(best_model, test_data_inputs, test_data_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "kqGqudhzT811"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis_trajectory_scatter(best_model, data_src_inputs, data_src_targets, lag_time = 10.0):\n",
    "  input_list, target_list, preds_list = get_predictions(best_model, data_src_inputs, data_src_targets)\n",
    "\n",
    "\n",
    "  min_val, max_val = 0, 50\n",
    "  \n",
    "  for i in range(0, len(input_list)):\n",
    "    # fig, ax = plt.subplots()\n",
    "    plt.figure(figsize=(3,3))\n",
    "    inputs = input_list[i]\n",
    "    targets = target_list[i]\n",
    "    preds = preds_list[i]\n",
    "\n",
    "    xy_inputs = []\n",
    "    xy_preds = []\n",
    "    xy_target = []\n",
    "\n",
    "\n",
    "    for inp in inputs:\n",
    "      cords = map_dict[inp] \n",
    "      xy_inputs.append(cords)\n",
    "\n",
    "    for inp in preds:\n",
    "      cords = map_dict[inp] \n",
    "      xy_preds.append(cords)\n",
    "\n",
    "    for inp in targets:\n",
    "      cords = map_dict[inp] \n",
    "      xy_target.append(cords)\n",
    "\n",
    "    x_inp, y_inp = zip(*xy_inputs)\n",
    "    x_tar, y_tar = zip(*xy_target)\n",
    "    x_pred, y_pred = zip(*xy_preds)\n",
    "\n",
    "    plt.scatter(x_inp,y_inp)\n",
    "    plt.scatter(x_tar,y_tar, color='r')\n",
    "    plt.scatter(x_pred,y_pred)\n",
    "\n",
    "    plt.xlim(0, 50)\n",
    "    plt.ylim(0, 50)\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Input: \", xy_inputs)\n",
    "    print(\"Preds: \", xy_preds)\n",
    "    print(\"Truth: \", xy_target)\n",
    "    time.sleep(lag_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "xr4Wjln7ev1D",
    "outputId": "845c14b8-e5f3-4267-be69-33c0c296814f"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6ac16c26e88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 10\n",
    "embedding_dim = 2\n",
    "embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "err = False\n",
    "if err:\n",
    "    #Any input more than input_dim - 1, here input_dim = 10\n",
    "    #Any input less than zero\n",
    "    input_to_embed = torch.tensor([10])\n",
    "else:\n",
    "    input_to_embed = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "embed = embedding(input_to_embed)\n",
    "print(embed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vehicle_David_Our_Transformer_from_scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
